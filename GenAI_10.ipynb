{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T14:00:24.980819Z",
     "iopub.status.busy": "2025-05-29T14:00:24.979255Z",
     "iopub.status.idle": "2025-05-29T14:01:35.116303Z",
     "shell.execute_reply": "2025-05-29T14:01:35.115028Z",
     "shell.execute_reply.started": "2025-05-29T14:00:24.980749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f290805b97459cbfb7f5cb83480dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bed2872127c453b9b9362b26d4b6835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04b635e8ac64dfb9f1d776e0a42ade0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc24c2ce6cf34c0ab759254280f37a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03bed92ca7b4d06803397cd13d14b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90bc255943a4ecdb8e4d85573dcdd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921ab71c223c453f8c4fc7de6c874603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dbd40ca03d4518bda79bcd5d6296b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510344196e9a4b0394a1bc60f965adfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59256659128645f0a26e6b0fabdf1476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23db8a349134400a82da35891102c117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de337f945b84af59ab9162f1a58d86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0294195d5bd74a678662bb27662d9539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/1527004487.py:48: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  return LLMChain(llm=llm, prompt=prompt).run(ipc_section=section, query=query)\n",
      "/tmp/ipykernel_35/1527004487.py:48: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return LLMChain(llm=llm, prompt=prompt).run(ipc_section=section, query=query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Simple Explanation:**\n",
      "The punishment for theft under the Indian Penal Code (IPC) depends on the circumstances and severity of the crime. Theft is considered a serious offense, and the law provides for various punishments, including imprisonment and fines.\n",
      "\n",
      "**Key Legal Points:**\n",
      "\n",
      "1. **Section 378 of the IPC**: This section defines theft and prescribes the punishment, which can be imprisonment for up to 3 years, or a fine, or both.\n",
      "2. **Section 390 of the IPC**: This section defines robbery, which is a more serious form of theft that involves violence or intimidation. Robbery is punishable under Section 392 of the IPC.\n",
      "3. **Section 392 of the IPC**: This section prescribes the punishment for robbery, which can be imprisonment for up to 10 years, or a fine, or both.\n",
      "4. **Aggravated forms of theft**: If the theft is committed in certain circumstances, such as in a dwelling house, or with the use of weapons, the punishment can be more severe.\n",
      "\n",
      "**Possible Punishments:**\n",
      "\n",
      "1. **Imprisonment**: Up to 3 years for theft, and up to 10 years for robbery.\n",
      "2. **Fine**: The court can impose a fine, which can be in addition to imprisonment.\n",
      "3. **Imprisonment for life**: In rare cases, where the offense is punishable under Section 377 of the IPC (related to unnatural offenses), the punishment can be imprisonment for life.\n",
      "\n",
      "**Real-World Example:**\n",
      "In a recent case, a person was caught stealing a laptop from a shop in Delhi. The accused was found to have used a duplicate key to unlock the shop and carry away the laptop. The court convicted the accused under Section 378 of the IPC (theft) and sentenced him to 2 years of imprisonment and a fine of â‚¹10,000. However, if the accused had used violence or intimidation to commit the theft, the court could have convicted him under Section 392 of the IPC (robbery) and sentenced him to a longer term of imprisonment.\n",
      "\n",
      "Note: The punishments mentioned above are subject to the discretion of the court and may vary depending on the specific circumstances of the case.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-groq -q\n",
    "!pip install groq PyMuPDF faiss-cpu sentence-transformers -q\n",
    "\n",
    "import os, fitz, faiss, numpy as np\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Setup\n",
    "os.environ[\"GROQ_API_KEY\"] = UserSecretsClient().get_secret(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# Load PDF and extract text\n",
    "def extract_text(path): return \"\\n\".join(page.get_text() for page in fitz.open(path))\n",
    "text = extract_text(\"/kaggle/input/ipc-pdf/IPC_186045.pdf\")\n",
    "\n",
    "# Create FAISS index\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_text(text)\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-V2\")\n",
    "embeddings = model.encode(chunks)\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# Search and respond\n",
    "def search_faiss(query):\n",
    "    q_embed = model.encode([query])\n",
    "    _, idx = index.search(np.array(q_embed), k=1)\n",
    "    return chunks[idx[0][0]]\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"ipc_section\", \"query\"],\n",
    "    template=\"\"\"You are an expert in Indian law. A user asked: \"{query}\"\n",
    "Based on the Indian Penal Code (IPC), the relevant section is:\n",
    "{ipc_section}\n",
    "Please provide:\n",
    "- A simple explanation\n",
    "- The key legal points\n",
    "- Possible punishments\n",
    "- A real-world example\"\"\"\n",
    ")\n",
    "\n",
    "def ipc_bot(query):\n",
    "    section = search_faiss(query)\n",
    "    return LLMChain(llm=llm, prompt=prompt).run(ipc_section=section, query=query)\n",
    "\n",
    "print(ipc_bot(\"What is the punishment for theft under IPC?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7546203,
     "sourceId": 11996678,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
