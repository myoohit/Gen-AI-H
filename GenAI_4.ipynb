{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2624724,"sourceType":"datasetVersion","datasetId":1595713}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install required packages\n!pip install -q groq\n\n# Imports\nfrom kaggle_secrets import UserSecretsClient\nimport groq\nfrom gensim.models import KeyedVectors\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer \nfrom sklearn.metrics.pairwise import cosine_similarity\nimport os\n\n# === Load Word2Vec Model ===\ndef load_word_vectors():\n    model_path = \"/kaggle/input/google-word2vec/GoogleNews-vectors-negative300.bin\"\n    model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n    print(\"word2vec loaded successfully!\")\n    return model\n\nmodel = load_word_vectors()\n\n# === Get Similar Words ===\ndef get_similar_words(word, model, topn=1):\n    try:\n        return [w[0] for w in model.most_similar(word, topn=topn)]\n    except KeyError:\n        return []\n\n# === Groq API Call ===\ndef generate_response(prompt, model_name=\"llama3-70b-8192\"):\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"GROQ_API_KEY\")\n    if not api_key:\n        raise ValueError(\"Missing GROQ_API_KEY secret.\")\n    \n    client = groq.Client(api_key=api_key)\n    response = client.chat.completions.create(\n        model=model_name,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n    return response.choices[0].message.content\n\n# === Enrich Prompt Using Word2Vec ===\ndef enrich_prompt(prompt, model, max_enrichments=2):\n    enriched = []\n    for word in prompt.split():\n        similar = [w for w in get_similar_words(word, model, topn=max_enrichments) if w.isalpha()]\n        enriched.append(f\"{word} ({', '.join(similar)})\" if similar else word)\n    return \" \".join(enriched)\n\n# === Compare Responses ===\ndef analyze_responses(original_response, enriched_response):\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform([original_response, enriched_response])\n    score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n    print(\"\\n==== Response Analysis ====\")\n    print(f\"Similarity Score: {score:.4f}\")\n    print(f\"Original Word Count: {len(original_response.split())}\")\n    print(f\"Enriched Word Count: {len(enriched_response.split())}\")\n\n# === RUN PIPELINE ===\noriginal_prompt = \"Describe the future of artificial intelligence in healthcare in 2 concise bullet points.\"\nenriched = enrich_prompt(original_prompt, model)\n\n# Output prompts\nprint(f\"Original Prompt:\\n{original_prompt}\")\nprint(f\"\\nEnriched Prompt:\\n{enriched}\")\n\n# Generate and print responses\noriginal_response = generate_response(original_prompt)\nenriched_response = generate_response(enriched)\n\nprint(f\"\\n==== Original Response ====\\n{original_response}\")\nprint(f\"\\n==== Enriched Response ====\\n{enriched_response}\")\n\n# Analyze responses\nanalyze_responses(original_response, enriched_response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T14:13:20.383532Z","iopub.execute_input":"2025-05-29T14:13:20.383901Z","iopub.status.idle":"2025-05-29T14:13:55.694004Z","shell.execute_reply.started":"2025-05-29T14:13:20.383871Z","shell.execute_reply":"2025-05-29T14:13:55.692984Z"}},"outputs":[{"name":"stdout","text":"word2vec loaded successfully!\nOriginal Prompt:\nDescribe the future of artificial intelligence in healthcare in 2 concise bullet points.\n\nEnriched Prompt:\nDescribe (Explain) the (this, in) future (furture) of artificial (artifical, Artificial) intelligence (Intelligence, intel) in (inthe, where) healthcare in (inthe, where) 2 concise (succinct, informative) bullet (bullets) points.\n\n==== Original Response ====\nHere are 2 concise bullet points that describe the future of artificial intelligence in healthcare:\n\n• **Personalized Medicine**: AI will analyze genomic data, medical records, and real-time health metrics to create tailored treatment protocols for individual patients, leading to more effective disease prevention, diagnosis, and treatment. AI-driven precision medicine will become the standard of care, improving patient outcomes and reducing healthcare costs.\n\n• **Augmented Clinical Decision-Making**: AI-powered tools will assist healthcare professionals in diagnosing and treating complex conditions, reducing diagnostic errors, and streamlining clinical workflows. AI will also help identify high-risk patients, enabling proactive interventions and improving healthcare resource allocation.\n\n==== Enriched Response ====\nHere are two concise bullet points describing the future of artificial intelligence in healthcare:\n\n• **Personalized Medicine**: AI will enable tailored healthcare treatments based on individual genetic profiles, medical histories, and real-time health data. AI-driven analytics will help clinicians identify high-risk patients, predict disease onset, and develop targeted interventions, leading to more effective treatments and improved patient outcomes.\n\n• **Autonomous Diagnostics**: AI-powered algorithms will increasingly assume responsibility for initial diagnosis, reducing the workload of healthcare professionals. AI-driven diagnostic tools will analyze medical images, lab results, and patient data to provide accurate and rapid diagnoses, freeing up human clinicians to focus on complex cases, patient care, and high-touch services.\n\n==== Response Analysis ====\nSimilarity Score: 0.6126\nOriginal Word Count: 100\nEnriched Word Count: 108\n","output_type":"stream"}],"execution_count":3}]}